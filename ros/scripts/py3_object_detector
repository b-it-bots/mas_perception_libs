#!/usr/bin/env python3

from importlib import import_module

import os
from abc import ABCMeta, abstractmethod
import yaml
from enum import Enum
import numpy as np

import rospy
import actionlib

from mas_perception_msgs.msg import BoundingBox2D, ObjectDetectionResult, DetectImageObjectsAction, DetectImageObjectsResult

import sys
try:
    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')
except:
    pass

class ImageDetectionKey(Enum):
    CLASS = 0
    CONF = 1
    X_MIN = 2
    X_MAX = 3
    Y_MIN = 4
    Y_MAX = 5

class ImageDetectorBase(object):
    """
    Abstract class for detecting things in images
    """
    __metaclass__ = ABCMeta

    _classes = None                 # type: dict
    # input size of model, will be ignored if left None
    _target_size = None             # type: tuple
    # preprocess function for each input image, will be ignored if left None
    _img_preprocess_func = None     # type: function

    def __init__(self, **kwargs):
        # load dictionary of classes
        class_file = kwargs.get('class_file', None)
        if class_file is not None and os.path.exists(class_file):
            with open(class_file, 'r') as infile:
                self._classes = yaml.load(infile)

        if self._classes is None:
            raise ValueError("no valid 'class_file' or 'classes' parameter specified")

        # load kwargs file and call load_model()
        model_kwargs_file = kwargs.get('model_kwargs_file', None)
        if model_kwargs_file is not None and os.path.exists(model_kwargs_file):
            with open(model_kwargs_file, 'r') as infile:
                load_model_kwargs = yaml.load(infile)
        else:
            load_model_kwargs = {}

        self.load_model(**load_model_kwargs)

    @property
    def classes(self):
        """ dictionary which maps prediction value (int) to class name (str) """
        return self._classes

    @abstractmethod
    def load_model(self, **kwargs):
        """
        To be implemented by extensions, where detection model is loaded

        :param kwargs: key word arguments necessary for the detection model
        :return: None
        """
        pass

    @abstractmethod
    def _detect(self, np_image, orig_img_size):
        """
        To be implemented by extensions, detect objects in given image messages

        :param np_images: list of numpy images extracted from image messages
        :param orig_img_sizes: list of original images' (width, height), necessary to map detected bounding boxes back
                               to the original images if the images are resized to fit the detection model input
        :return: List of predictions for each image. Each prediction is a list of dictionaries representing the detected
                 classes with their bounding boxes and confidences. The dictionary keys are values of the
                 ImageDetectionKey Enum.
        """
        pass

    def detect(self, image_array_msg):
        """
        Preprocess image messages then call abstract method _detect() on the processed images

        :param image_messages: list of sensor_msgs/Image
        :return: same with _detect()
        """
        orig_img_size = (image_array_msg.width, image_array_msg.height)
        np_image = np.reshape((image_array_msg.image),
                              (image_array_msg.height, image_array_msg.width, 3))
        return self._detect(np_image, orig_img_size)

    @staticmethod
    def prediction_to_bounding_boxes(prediction):
        """
        Create BoundingBox2D objects from a prediction result

        :param prediction: List of dictionaries representing detected classes in an image. Keys are values of
                           ImageDetectionKey Enum
        :param color_dict: Dictionary mapping class name to a color tuple (r, g, b). Default color is blue.
        :return: List of BoundingBox2D objects, one for each predicted class
        """
        result_msg = ObjectDetectionResult()
        for box_dict in prediction:
            bounding_box = BoundingBox2D()
            bounding_box.min_x = box_dict[ImageDetectionKey.X_MIN]
            bounding_box.max_x = box_dict[ImageDetectionKey.X_MAX]
            bounding_box.min_y = box_dict[ImageDetectionKey.Y_MIN]
            bounding_box.max_y = box_dict[ImageDetectionKey.Y_MAX]

            result_msg.bounding_boxes.append(bounding_box)
            result_msg.classes.append(box_dict[ImageDetectionKey.CLASS])
            result_msg.confidences.append(box_dict[ImageDetectionKey.CONF])
        return result_msg

class TorchImageDetector(ImageDetectorBase):
    _model = None
    _detection_threshold = 0.
    _eval_device = None

    def __init__(self, **kwargs):
        import torch
        self._eval_device = torch.device('cuda') if torch.cuda.is_available() \
                                                 else torch.device('cpu')
        super(TorchImageDetector, self).__init__(**kwargs)

    def load_model(self, **kwargs):
        import torch

        detector_module = kwargs.get('detector_module', None)
        detector_instantiator = kwargs.get('detector_instantiator', None)
        self._detection_threshold = kwargs.get('detection_threshold', 0.)
        model_path = kwargs.get('model_path', None)

        rospy.loginfo('[load_model] Received the following model parameters:')
        rospy.loginfo('detection_module: %s', detector_module)
        rospy.loginfo('detection_instantiator: %s', detector_instantiator)
        rospy.loginfo('detection_threshold: %f', self._detection_threshold)
        rospy.loginfo('model_path: %s', model_path)
        try:
            if model_path is None:
                rospy.logwarn('[load_model] model_path not specified; loading a pretrained model')

                detector_instantiator = getattr(import_module(detector_module),
                                                detector_instantiator)
                self._model = detector_instantiator(pretrained=True)
            else:
                rospy.loginfo('[load_model] Instantiating model')
                detector_instantiator = getattr(import_module(detector_module),
                                                detector_instantiator)
                self._model = detector_instantiator(len(self._classes.keys()))

                rospy.loginfo('[load_model] Loading model parameters from %s', model_path)
                checkpoint = torch.load(model_path, map_location=self._eval_device)
                self._model.load_state_dict(checkpoint['model'])
                rospy.loginfo('[load_model] Successfully loaded model')

            self._model.eval()
            self._model.to(self._eval_device)
        except TypeError as exc:
            rospy.logerr('[load_model] Error loading model')
            raise

    def _detect(self, image, orig_img_size):
        import torch
        from torchvision.transforms import functional

        # the elements of the input image have type float64, but we convert
        # them to uint8 since the evaluation is quite slow otherwise
        image = np.array(image, dtype=np.uint8)

        img_tensor = functional.to_tensor(image)
        model_predictions = None
        with torch.no_grad():
            model_predictions = self._model([img_tensor.to(self._eval_device)])
        detected_obj_data = TorchImageDetector.process_predictions(model_predictions[0],
                                                                   self._classes,
                                                                   self._detection_threshold)
        return detected_obj_data

    @staticmethod
    def process_predictions(predictions, classes, detection_threshold):
        '''Returns a list of dictionaries describing all object detections in
        "predictions". Each dictionary contains six entries:
        * the object class
        * the prediction confidence
        * four entries for the bounding box prediction described through min/max pixels over x and y

        predictions: Dict[str, Tensor] -- A dictionary containing three entries -
                                          ("boxes", "labels", and "scores") - which
                                          describe object predictions
        classes: Dict[int, str] -- A map of class labels to class names
        detection_threshold: float -- Detection threshold (between 0 and 1)

        '''
        pred_class = [classes[i] if i in classes else 'unknown'
                      for i in list(predictions['labels'].cpu().numpy())]
        pred_boxes = [[(i[0], i[1]), (i[2], i[3])]
                      for i in list(predictions['boxes'].cpu().detach().numpy())]
        pred_score = list(predictions['scores'].cpu().detach().numpy())
        pred_t = [i for i, x in enumerate(pred_score) if x > detection_threshold]

        detected_obj_data = []
        if pred_t:
            pred_t = pred_t[-1]
            pred_boxes = pred_boxes[:pred_t+1]
            pred_class = pred_class[:pred_t+1]
            pred_score = pred_score[:pred_t+1]

            num_detected_objects = len(pred_boxes)
            for i in range(num_detected_objects):
                # the results have numpy types, so we type cast them to
                # native Python types before including them in the result
                obj_data_dict = {ImageDetectionKey.CLASS: str(pred_class[i]),
                                 ImageDetectionKey.CONF: float(pred_score[i]),
                                 ImageDetectionKey.X_MIN: float(pred_boxes[i][0][0]),
                                 ImageDetectionKey.Y_MIN: float(pred_boxes[i][0][1]),
                                 ImageDetectionKey.X_MAX: float(pred_boxes[i][1][0]),
                                 ImageDetectionKey.Y_MAX: float(pred_boxes[i][1][1])}
                detected_obj_data.append(obj_data_dict)
        return detected_obj_data

class SingleImageDetectionHandler(object):
    """
    Simple handler for ImageDetectorBase class which publishes visualized detection result for a single image message
    on a specified topic if there're subscribers. Needs to be run within a node.
    """
    _detector = None    # type: ImageDetectorBase
    _result_pub = None  # type: rospy.Publisher

    def __init__(self):
        class_annotation_file = rospy.get_param('~class_annotations', '')
        kwargs_file = rospy.get_param('~kwargs_file', '')
        action_name = rospy.get_param('~detection_action_name',
                                      '/mas_perception/detect_image_objects')

        self._detector = TorchImageDetector(class_file=class_annotation_file,
                                            model_kwargs_file=kwargs_file)

        self.action_server = actionlib.SimpleActionServer(action_name,
                                                          DetectImageObjectsAction,
                                                          self.process_image_msg, False)
        self.action_server.start()
        rospy.loginfo('Object detection server ready')

    def process_image_msg(self, goal):
        predictions = self._detector.detect(goal.image_array)
        rospy.loginfo("publishing detection result")
        result = DetectImageObjectsResult()
        result.detections = ImageDetectorBase.prediction_to_bounding_boxes(predictions)
        self.action_server.set_succeeded(result)


if __name__ == '__main__':
    rospy.init_node('object_detection')
    image_handler = SingleImageDetectionHandler()
    while not rospy.is_shutdown():
        try:
            rospy.sleep(0.1)
        except rospy.ROSInterruptException:
            rospy.loginfo('Killing node')
